{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7cd011f",
   "metadata": {},
   "source": [
    "<span style=\"font-family:Calibri; font-size:3em;\">Handwritten Digits Classifier</span>\n",
    "\n",
    "<span style=\"font-family:Calibri; font-size:1.5em;\">A guided project with UCI data set</span>\n",
    "\n",
    "![Image](https://cdn-images-1.medium.com/max/2400/1*LmxW8FDfXZJl5yvESvjP7Q.jpeg)\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this project, we'll explore different approaches to image classification using traditional machine learning algorithms and deep learning.\n",
    "\n",
    "We'll be working with [hand-written digits dataset](http://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits) from UCI. Luckily the `sklearn` library has built-in function that returns the exact copy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29eea81",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits(as_frame=True)\n",
    "print(digits.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b66f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "digits.frame.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8985ed",
   "metadata": {},
   "source": [
    "The data set has **1797** images are represented as a row of pixel values. Since each row contain **64** values our images have **8x8** resolution.\n",
    "\n",
    "Let's display some of them using `matplotlib`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae43062",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "fix, axs = plt.subplots(2, 4, figsize=(16,9))\n",
    "digits_df = digits.data\n",
    "bias = 0\n",
    "\n",
    "for row in range(2):\n",
    "    for col in range(4):\n",
    "        #Calculate index for each image\n",
    "        #It would be 1100 for second bottom image for exaple \n",
    "        index = col * 100 + bias\n",
    "        image = digits_df.iloc[index].values.reshape(8,8)\n",
    "        axs[row, col].imshow(image, cmap='gray_r')\n",
    "        \n",
    "    bias = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1358576",
   "metadata": {},
   "source": [
    "## KNN classifier\n",
    "\n",
    "Due to there is no linearity between image's pixels and an actiual digit we'll use the k-nearest neighbors algorithm here. The `KNeighborsClassifier` to be precise.\n",
    "\n",
    "Let's define a few functions and run them with **k=5** and **folds=4**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a8f974",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def train_test(train_set, test_set, k, how='train'):\n",
    "    #trains and tests k-nearest neighbors models with different k\n",
    "    \n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(train_set.iloc[:, :-1], train_set['target'])\n",
    "    \n",
    "    #uses train or test sets in predict() depending on how\n",
    "    if how == 'train':\n",
    "        prediction = knn.predict(train_set.iloc[:, :-1])\n",
    "        accuracy = accuracy_score(train_set['target'], prediction)\n",
    "        return accuracy\n",
    "    \n",
    "    elif how == 'test':\n",
    "        prediction = knn.predict(test_set.iloc[:, :-1])\n",
    "        accuracy = accuracy_score(test_set['target'], prediction)\n",
    "        return accuracy\n",
    "    \n",
    "def cross_validate(data, k, how='train'):\n",
    "    #performs 4-fold cross validation using train() and test()\n",
    "    #returns overall accuracy\n",
    "    \n",
    "    kf = KFold(n_splits=4,\n",
    "              shuffle=True,\n",
    "              random_state=0)\n",
    "    \n",
    "    accuracies = []\n",
    "    \n",
    "    for train_index, test_index in kf.split(data):\n",
    "        \n",
    "        train_set = data.iloc[train_index]\n",
    "        test_set = data.iloc[test_index]\n",
    "\n",
    "        accuracy = train_test(train_set, test_set, k, how)\n",
    "        accuracies.append(accuracy)\n",
    "        \n",
    "    return np.mean(accuracies)\n",
    "\n",
    "cross_validate(digits.frame, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4be2c3",
   "metadata": {},
   "source": [
    "Now let's iterate number of neigbors and build a plot for computed accuracies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67edd9be",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "knn_accuracies = pd.DataFrame(index=range(1,36), columns=['train', 'test'])\n",
    "\n",
    "methods = ['train', 'test']\n",
    "\n",
    "#Iterate over both methods and 25 neigbors numbers\n",
    "for how in methods:\n",
    "    for k in range(1,36):\n",
    "        accuracy = cross_validate(digits.frame, k, how)\n",
    "        knn_accuracies.loc[k, how] = accuracy\n",
    "    \n",
    "knn_accuracies.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb065ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16,9))\n",
    "\n",
    "for col in knn_accuracies.columns:\n",
    "    ax.plot(knn_accuracies[col],\n",
    "           lw=5)\n",
    "\n",
    "#decorations\n",
    "ax.set_xlim(1, 35)\n",
    "ax.set_title('Mean accuracy vs k-value', fontsize=20)\n",
    "ax.tick_params(labelsize=14)\n",
    "ax.legend(['Train accuracy', 'Test accuracy'],\n",
    "         fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d684b2e8",
   "metadata": {},
   "source": [
    "It seems the best result's achived with **k=1**, **0.986** on test set and **1** on train. Both accurasies are extreamly high due to we use in-build dataset. Also increasing k-value doesn't make our predictions more accurate.\n",
    "\n",
    "Also we can observe the difference between train and test accuracies which is signal of overfitting. But increasing k-value decreases this difference. For example, with **k=25** we'got **0.969** and\t**0.966** for train and test sets respectively.\n",
    "\n",
    "We'll stick to these results and try to improve this result with neural network.\n",
    "\n",
    "## MLP classifier\n",
    "\n",
    "There are a few downsides to using k-nearest neighbors:\n",
    "* high memory usage (for each new unseen observation, many comparisons need to be made to seen observations)\n",
    "* no model representation to debug and explore\n",
    "\n",
    "Considering this we'll try a neural network with a single hidden layer but with different number of neurons. We'll keep using cross validation with 4 folds at this try as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e69a40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "def mlp_cross_val(data, n):\n",
    "    #performs 4-fold cross validation using MLPClassifier\n",
    "    #returns overall accuracies\n",
    "    \n",
    "    kf = KFold(n_splits=4,\n",
    "              shuffle=True,\n",
    "              random_state=0)\n",
    "    \n",
    "    train_accuracies = []\n",
    "    test_accuracies = []\n",
    "    \n",
    "    for train_index, test_index in kf.split(data):\n",
    "        \n",
    "        train_set = data.iloc[train_index]\n",
    "        test_set = data.iloc[test_index]\n",
    "        \n",
    "        mlp_class = MLPClassifier(hidden_layer_sizes=(n,),\n",
    "                                  solver='sgd',\n",
    "                                  max_iter=300,\n",
    "                                  learning_rate_init=0.02,\n",
    "                                  random_state=0)\n",
    "        \n",
    "        mlp_class.fit(train_set.iloc[:, :-1], train_set['target'])\n",
    "        \n",
    "        #Use train or test sets in score() depending on how\n",
    "        train_accuracy = mlp_class.score(train_set.iloc[:, :-1],\n",
    "                                       train_set['target'])\n",
    "\n",
    "        test_accuracy = mlp_class.score(test_set.iloc[:, :-1],\n",
    "                                       test_set['target'])\n",
    "\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        test_accuracies.append(test_accuracy)\n",
    "        \n",
    "    return np.mean(train_accuracies), np.mean(test_accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b014a372",
   "metadata": {},
   "source": [
    "Now we've got `mlp_cross_val()` func, let's iterate through different neurons number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f1a596",
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons = np.around(np.geomspace(8, 256, num=6)).astype(int) #also index\n",
    "\n",
    "neurons_accuracies = pd.DataFrame(index=neurons, columns=['train', 'test'])\n",
    "\n",
    "#Iterate over 6 neurons numbers\n",
    "for neuron in neurons:\n",
    "    train_acc, test_acc = mlp_cross_val(digits.frame, neuron)\n",
    "    neurons_accuracies.loc[neuron, 'train'] = train_acc\n",
    "    neurons_accuracies.loc[neuron, 'test'] = test_acc\n",
    "\n",
    "neurons_accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1528b16",
   "metadata": {},
   "source": [
    "And now we'll build a plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9dcbfed",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16,9))\n",
    "\n",
    "for col in neurons_accuracies.columns:\n",
    "    ax.plot(neurons_accuracies[col],\n",
    "           lw=5)\n",
    "\n",
    "#decorations\n",
    "ax.set_xlim(8, 256)\n",
    "ax.set_title('Mean accuracy vs neurons number', fontsize=20)\n",
    "ax.tick_params(labelsize=14)\n",
    "ax.legend(['Train accuracy', 'Test accuracy'],\n",
    "         fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c0feb5",
   "metadata": {},
   "source": [
    "Our model's accuracy hit **1** pretty fast on train set while it's a bit lower on test set. But train accuracy is increasing with number of neurons in the hidden layer. It reaches **0.976** with **256** neurons but it's still worse than knn classification gave us. And there is still overfitting.\n",
    "\n",
    "Would it be more effective to use more layers? Let's find out!\n",
    "\n",
    "## Multilayer network\n",
    "\n",
    "We'll start with one additional layer and use the same neurons numbers. Let's update `mlp_cross_val()` for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb95e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_cross_val(data, n, layers=1):\n",
    "    #performs 4-fold cross validation using MLPClassifier\n",
    "    #returns overall accuracy\n",
    "    \n",
    "    kf = KFold(n_splits=4,\n",
    "              shuffle=True,\n",
    "              random_state=0)\n",
    "    \n",
    "    train_accuracies = []\n",
    "    test_accuracies = []\n",
    "    \n",
    "    #Create a tuple with n nerouns in layers\n",
    "    hidden_layers = tuple([n for layer in range(layers)])\n",
    "    \n",
    "    for train_index, test_index in kf.split(data):\n",
    "        \n",
    "        train_set = data.iloc[train_index]\n",
    "        test_set = data.iloc[test_index]\n",
    "        \n",
    "        mlp_class = MLPClassifier(hidden_layer_sizes=hidden_layers,\n",
    "                                  solver='sgd',\n",
    "                                  max_iter=300,\n",
    "                                  learning_rate_init=0.02,\n",
    "                                  random_state=0)\n",
    "        \n",
    "        mlp_class.fit(train_set.iloc[:, :-1], train_set['target'])\n",
    "        \n",
    "        #Use train or test sets in score() depending on how\n",
    "        train_accuracy = mlp_class.score(train_set.iloc[:, :-1],\n",
    "                                       train_set['target'])\n",
    "\n",
    "        test_accuracy = mlp_class.score(test_set.iloc[:, :-1],\n",
    "                                       test_set['target'])\n",
    "\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        test_accuracies.append(test_accuracy)\n",
    "        \n",
    "    return np.mean(train_accuracies), np.mean(test_accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fe99be",
   "metadata": {},
   "source": [
    "Now we'll use our function with different hyperparameters. And for that we'll create another func!\n",
    "\n",
    "The `accurasies_plot_nn()` function will train NN with defined layers parameters and add resulting mean accuracy with NN hyperparameters to the `neurons_accuracies`. It will also build a \"Mean accuracy vs neurons number\" plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480ed784",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accurasies_plot_nn(data, layer, neurons):\n",
    "    #Iterate over both methods and neurons\n",
    "    for neuron in neurons:\n",
    "        new_row = [layer, neuron]\n",
    "        accuracies = mlp_cross_val(data, neuron, layer)\n",
    "        new_row.extend(list(accuracies))\n",
    "        neurons_accuracies.loc[len(neurons_accuracies)] = new_row\n",
    "    \n",
    "    #Build plot\n",
    "    fig, ax = plt.subplots(figsize=(16,9))\n",
    "    columns = ['train', 'test']\n",
    "    layer_accuracies = neurons_accuracies[neurons_accuracies['layers'] == layer]\n",
    "    \n",
    "    for col in columns:\n",
    "        ax.plot(layer_accuracies['neurons'], \n",
    "                layer_accuracies[col],\n",
    "               lw=5)\n",
    "\n",
    "    #decorations\n",
    "    ax.set_xlim(8, 256)\n",
    "    ax.set_title('Mean accuracy vs neurons number', fontsize=20)\n",
    "    ax.tick_params(labelsize=14)\n",
    "    ax.legend(['Train accuracy', 'Test accuracy'],\n",
    "             fontsize=14,\n",
    "             loc='lower right')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674eb53c",
   "metadata": {},
   "source": [
    "Also let's prepare `neurons_accuracies` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cec9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modify accuracies df\n",
    "neurons_accuracies.reset_index(inplace=True)\n",
    "neurons_accuracies.rename(columns={'index': 'neurons'}, inplace=True)\n",
    "neurons_accuracies.insert(0, \"layers\", 1)\n",
    "\n",
    "neurons_accuracies.tail(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd81b0e6",
   "metadata": {},
   "source": [
    "### Two hidden layers\n",
    "\n",
    "Two hidden layers NN, here we go! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6ef1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "accurasies_plot_nn(digits.frame, 2, neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773b4a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons_accuracies.tail(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e6a504",
   "metadata": {},
   "source": [
    "Our best shot brought us **0.978** accuracy with **256** neurons and it's the worst result so far for the NN.\n",
    "\n",
    "### Three hidden layers\n",
    "\n",
    "Let's try 3 hidden layers this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0958e85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "accurasies_plot_nn(digits.frame, 3, neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a5364a",
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons_accuracies.tail(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45279cf5",
   "metadata": {},
   "source": [
    "Using one additional layer doesn't improve accuracy at all and tends to overfitting. We should try different approach.\n",
    "\n",
    "## Activation functions\n",
    "\n",
    "MLPClassifier uses [ReLU](https://en.wikipedia.org/wiki/Rectifier_(neural_networks)) by default. We can change it to [sigmoid](https://en.wikipedia.org/wiki/Sigmoid_function) and [hyperbolic tan function](https://en.wikipedia.org/wiki/Hyperbolic_functions). There is also identity function but we leave it.\n",
    "\n",
    "We'll test both function with one hidden layer. Let's update our functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1a37e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_cross_val(data, n, layers=1, func='relu'):\n",
    "    #performs 4-fold cross validation using MLPClassifier\n",
    "    #returns overall accuracy\n",
    "    \n",
    "    kf = KFold(n_splits=4,\n",
    "              shuffle=True,\n",
    "              random_state=0)\n",
    "    \n",
    "    train_accuracies = []\n",
    "    test_accuracies = []\n",
    "    \n",
    "    #Create a tuple with n nerouns in layers\n",
    "    hidden_layers = tuple([n for layer in range(layers)])\n",
    "    \n",
    "    for train_index, test_index in kf.split(data):\n",
    "        \n",
    "        train_set = data.iloc[train_index]\n",
    "        test_set = data.iloc[test_index]\n",
    "        \n",
    "        mlp_class = MLPClassifier(hidden_layer_sizes=hidden_layers,\n",
    "                                  max_iter=1100, #for sigmoid convergence\n",
    "                                  solver='sgd',\n",
    "                                  learning_rate_init=0.02,\n",
    "                                  random_state=0,\n",
    "                                  activation=func)\n",
    "        \n",
    "        mlp_class.fit(train_set.iloc[:, :-1], train_set['target'])\n",
    "        \n",
    "        #Use train or test sets in score() depending on how\n",
    "        train_accuracy = mlp_class.score(train_set.iloc[:, :-1],\n",
    "                                       train_set['target'])\n",
    "\n",
    "        test_accuracy = mlp_class.score(test_set.iloc[:, :-1],\n",
    "                                       test_set['target'])\n",
    "\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        test_accuracies.append(test_accuracy)\n",
    "        \n",
    "    return np.mean(train_accuracies), np.mean(test_accuracies)\n",
    "\n",
    "def accurasies_nn(data, layers, neurons, func='relu'):\n",
    "    #Iterate over both methods and neurons and layers\n",
    "    for layer in layers:\n",
    "        for neuron in neurons:\n",
    "            new_row = [layer, neuron]\n",
    "            accuracies = mlp_cross_val(data, neuron, layer, func)\n",
    "            new_row.extend(list(accuracies))\n",
    "            new_row.append(func)\n",
    "            neurons_accuracies.loc[len(neurons_accuracies)] = new_row      \n",
    "            \n",
    "\n",
    "\n",
    "def nn_plot(func):    \n",
    "    #Build plots\n",
    "    fig, axs = plt.subplots(3, 1, figsize=(16,18))\n",
    "    plt.suptitle('Mean accuracies {} function'.format(func), size=26)\n",
    "    columns = ['train', 'test']\n",
    "    \n",
    "    for i in range(3):\n",
    "        #Filter our df\n",
    "        mask = (neurons_accuracies['layers'] == (i + 1)) & (neurons_accuracies['func'] == func)\n",
    "        layer_accuracies = neurons_accuracies[mask]\n",
    "        \n",
    "        for col in columns:\n",
    "            axs[i].plot(layer_accuracies['neurons'], \n",
    "                       layer_accuracies[col],\n",
    "                       lw=4)\n",
    "\n",
    "            #decorations\n",
    "            axs[i].set_xlim(8, 256)\n",
    "            axs[i].set_title('{} hidden layers'.format(i + 1), fontsize=20)\n",
    "            axs[i].tick_params(labelsize=14)\n",
    "            axs[i].legend(['Train accuracy', 'Test accuracy'],\n",
    "                         fontsize=14,\n",
    "                         loc='lower right')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb72af9b",
   "metadata": {},
   "source": [
    "### Sigmoid func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd068bd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "neurons_accuracies['func'] = 'relu'\n",
    "\n",
    "function = ['logistic', 'tanh']\n",
    "layers = [1, 2 ,3]\n",
    "\n",
    "accurasies_nn(digits.frame, layers, neurons, function[0])\n",
    "neurons_accuracies.tail(18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275ca089",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nn_plot(function[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d1a354",
   "metadata": {},
   "source": [
    "### Tanh func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba3f15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "accurasies_nn(digits.frame, layers, neurons, function[1])\n",
    "neurons_accuracies.tail(18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e46c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_plot(function[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf6283e",
   "metadata": {},
   "source": [
    "Okay, we've tried all three activation functions so far and even beaten the KNN results. We've got **0.982** accuracy with **logistic** func and **1** hidden layers **256** neurons each.\n",
    "\n",
    "But all our models seem to be too **\"perfect\"**, to be **overfitted**. Regardless of hyperparameters we're still getting train accuracies close to or even **equal 1**, while test accuracies are quite lower. This gap decreases with increasing complexity of NN (especially tanh) but it doesn't solve our problem.\n",
    "\n",
    "Our best results are down below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad5fbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons_accuracies.groupby(['func', 'layers'])['test'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105ef900",
   "metadata": {},
   "source": [
    "## Grid Search\n",
    "\n",
    "We've tried to find our best hyperparameters by manually iterating over them until now. But `sklearn` has wonderful `GridSearchCV` class that make it on his own.\n",
    "\n",
    "Let's try it with the previous sets of hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9161e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#Prepare hidden layers config\n",
    "hdn = []\n",
    "\n",
    "for layers in range(1,4):\n",
    "    for n in neurons:\n",
    "        hidden_layer = tuple([n for layer in range(layers)])\n",
    "        hdn.append(hidden_layer)\n",
    "        \n",
    "#function.append('relu')\n",
    "\n",
    "parameter_space = {'hidden_layer_sizes': hdn,\n",
    "                  'activation': function}\n",
    "\n",
    "mlp = MLPClassifier(max_iter=1100,\n",
    "                    solver='sgd',\n",
    "                    learning_rate_init=0.02,\n",
    "                    random_state=0)\n",
    "\n",
    "kf = KFold(n_splits=4,\n",
    "           shuffle=True,\n",
    "           random_state=0)\n",
    "\n",
    "clf = GridSearchCV(mlp, parameter_space, n_jobs=-1, cv=kf)\n",
    "clf.fit(digits.data, digits.target)\n",
    "\n",
    "print(clf.best_params_, clf.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210971de",
   "metadata": {},
   "source": [
    "Grid search results are exact the same with much easier pipeline:\n",
    "\n",
    "* **0.982** accuracy\n",
    "* **128**\n",
    "* **1** layer\n",
    "* **logistic** activation function\n",
    "\n",
    "But we still have overfitting problem to solve.\n",
    "\n",
    "## L2 regularization\n",
    "\n",
    "Now we'll use our ultimate weapon - [L2 regularization](https://towardsdatascience.com/intuitions-on-l1-and-l2-regularisation-235f2db4c261).\n",
    "\n",
    "MLPClassifier has special parameter `alpha` for that which we'll be manually changing. Let's first update the `mlp_cross_val()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4820e91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_cross_val(data, n=8, layers=1, func='relu', alpha=0.0001):\n",
    "    #performs 4-fold cross validation using MLPClassifier\n",
    "    #returns overall accuracy\n",
    "    \n",
    "    kf = KFold(n_splits=4,\n",
    "              shuffle=True,\n",
    "              random_state=0)\n",
    "    \n",
    "    train_accuracies = []\n",
    "    test_accuracies = []\n",
    "    \n",
    "    #Create a tuple with n nerouns in layers\n",
    "    hidden_layers = tuple([n for layer in range(layers)])\n",
    "    \n",
    "    for train_index, test_index in kf.split(data):\n",
    "        \n",
    "        train_set = data.iloc[train_index]\n",
    "        test_set = data.iloc[test_index]\n",
    "        \n",
    "        mlp_class = MLPClassifier(hidden_layer_sizes=hidden_layers,\n",
    "                                  max_iter=1100,\n",
    "                                  learning_rate_init=0.02,\n",
    "                                  random_state=0,\n",
    "                                  activation=func,\n",
    "                                  alpha=alpha)\n",
    "        \n",
    "        mlp_class.fit(train_set.iloc[:, :-1], train_set['target'])\n",
    "        \n",
    "        #Use train or test sets in score() depending on how\n",
    "        train_accuracy = mlp_class.score(train_set.iloc[:, :-1],\n",
    "                                       train_set['target'])\n",
    "\n",
    "        test_accuracy = mlp_class.score(test_set.iloc[:, :-1],\n",
    "                                       test_set['target'])\n",
    "\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        test_accuracies.append(test_accuracy)\n",
    "        \n",
    "        return np.mean(train_accuracies), np.mean(test_accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e981fa9d",
   "metadata": {},
   "source": [
    "We'll iterate alpha with the hidden layers parameters that gave us the best test accuracy which is:\n",
    "* **0.982** accuracy\n",
    "* **256**\n",
    "* **1** layer\n",
    "* **logistic** activation function\n",
    "\n",
    "Let's try to fight overfitting!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff31ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare alpha values and special df\n",
    "alphas = np.linspace(0.0001, 5, 200)\n",
    "\n",
    "alpha_df = pd.DataFrame({'layers': 1,\n",
    "                         'neurons': 256,\n",
    "                         'alpha': alphas,\n",
    "                         'train': np.nan,\n",
    "                         'test': np.nan})\n",
    "\n",
    "#Iterate through alpha values\n",
    "for alpha in alphas:\n",
    "    accuracies = mlp_cross_val(digits.frame, 256,\n",
    "                             func='logistic',\n",
    "                             alpha=alpha)\n",
    "    \n",
    "    alpha_df.loc[alpha_df['alpha'] == alpha, 'train'] = accuracies[0]\n",
    "    alpha_df.loc[alpha_df['alpha'] == alpha, 'test'] = accuracies[1]\n",
    "        \n",
    "alpha_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d190923a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16,9))\n",
    "columns = ['train', 'test']\n",
    "    \n",
    "for col in columns:\n",
    "    ax.plot(alpha_df['alpha'], \n",
    "            alpha_df[col],\n",
    "            lw=5)\n",
    "\n",
    "#Decorations\n",
    "ax.set_title('Mean accuracy vs alpha', fontsize=20)\n",
    "ax.tick_params(labelsize=14)\n",
    "ax.legend(['Train accuracy', 'Test accuracy'],\n",
    "            fontsize=14,\n",
    "            loc='lower right')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797b157b",
   "metadata": {},
   "source": [
    "When alpha is somewher between 2 and 4 train accuracy decreases to test one which is almost on the same level from initial alpha.\n",
    "\n",
    "Let's explore this interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d21ee2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_mask = (alpha_df['alpha'] >= 2) & (alpha_df['alpha'] <= 4)\n",
    "\n",
    "alpha_df[alpha_mask].sort_values('test', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbac2e0f",
   "metadata": {},
   "source": [
    "We've got some intresting results. Two models have slightly higher test accuracy which means we're about over regularization. For example **123** iteration with the difference is **-0.000064**. It's sign of over regularization.\n",
    "\n",
    "We'll take **114** row as our best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f163d5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_alpha = alpha_df.iloc[114, 2]\n",
    "\n",
    "alpha_df.iloc[114, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0d92ae",
   "metadata": {},
   "source": [
    "Now we can say for sure that which hyperparameters we should use.\n",
    "\n",
    "## Visualization of MLP Weights\n",
    "\n",
    "In this paragraph we'll research visualization of MLP weights using [sklearn article](https://scikit-learn.org/stable/auto_examples/neural_networks/plot_mnist_filters.html) as example. Weights picture can give us some insights about neural network behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c1d074",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#MLP with best hp\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(256,),\n",
    "                    activation='logistic',\n",
    "                    max_iter=1100,\n",
    "                    alpha=best_alpha,\n",
    "                    solver='sgd',\n",
    "                    random_state=0,\n",
    "                    learning_rate_init=0.02)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    digits.data, digits.target, test_size=0.25, random_state=0)\n",
    "\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "fig, axes = plt.subplots(16, 16, figsize=(16,16))\n",
    "plt.suptitle('Weights between input and hidden layer', size=26)\n",
    "\n",
    "#Use global min/max to ensure all weights are shown on the same scale\n",
    "vmin, vmax = mlp.coefs_[0].min(), mlp.coefs_[0].max()\n",
    "\n",
    "for coef, ax in zip(mlp.coefs_[0].T, axes.ravel()):\n",
    "    ax.matshow(coef.reshape(8, 8), cmap=plt.cm.gray, vmin=.5 * vmin,\n",
    "               vmax=.5 * vmax)\n",
    "    ax.set_xticks(())\n",
    "    ax.set_yticks(())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669fa234",
   "metadata": {},
   "source": [
    "Weights look very structured. We even can see something like numbers in there. This is a good sign of model perfomance.\n",
    "\n",
    "## Conclusions\n",
    "\n",
    "In this project we've researched how MLP classifier behaves with different hyperparameters. We've tried \n",
    "\n",
    "We've seen that making neural network more complex doesn't necessarily improve predictions. Actually it makes the opposite and tends to overfitting.\n",
    "\n",
    "We've used powerful L2 regularization to fight it and succeeded. Finally we've built weights picture which uncovers network hidden work.   \n",
    "\n",
    "Further we could add made some more improvements to the model like momemntum or early stopping and test it. Also we could experiment with folds number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f543aa99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "\n",
    "# Set that the color channel value will be first\n",
    "K.set_image_data_format(\"channels_last\")\n",
    "\n",
    "# Set seed\n",
    "np.random.seed(0)\n",
    "\n",
    "# Set image information\n",
    "channels = 1\n",
    "height = 28\n",
    "width = 28\n",
    "\n",
    "# Load data and target from MNIST data\n",
    "(data_train, target_train), (data_test, target_test) = mnist.load_data()\n",
    "\n",
    "# Reshape training image data into features\n",
    "data_train = data_train.reshape(data_train.shape[0], height, width, channels)\n",
    "\n",
    "# Reshape test image data into features\n",
    "data_test = data_test.reshape(data_test.shape[0], height, width, channels)\n",
    "\n",
    "# Rescale pixel intensity to between 0 and 1\n",
    "features_train = data_train / 255\n",
    "features_test = data_test / 255\n",
    "\n",
    "# One-hot encode target\n",
    "target_train = np_utils.to_categorical(target_train)\n",
    "target_test = np_utils.to_categorical(target_test)\n",
    "number_of_classes = target_test.shape[1]\n",
    "\n",
    "def create_network(optimizer):\n",
    "    # Start neural network\n",
    "    network = Sequential()\n",
    "\n",
    "    # Add convolutional layer with 64 filters, a 5x5 window, and ReLU activation function\n",
    "    network.add(Conv2D(filters=64,\n",
    "                   kernel_size=(5, 5),\n",
    "                   input_shape=(width, height, channels),\n",
    "                   activation='relu'))\n",
    "\n",
    "    # Add max pooling layer with a 2x2 window\n",
    "    network.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    # Add dropout layer\n",
    "    network.add(Dropout(0.5))\n",
    "\n",
    "    # Add layer to flatten input\n",
    "    network.add(Flatten())\n",
    "\n",
    "    # # Add fully connected layer of 128 units with a ReLU activation function\n",
    "    network.add(Dense(128, activation=\"relu\"))\n",
    "\n",
    "    # Add dropout layer\n",
    "    network.add(Dropout(0.5))\n",
    "\n",
    "    # Add fully connected layer with a softmax activation function\n",
    "    network.add(Dense(number_of_classes, activation=\"softmax\"))\n",
    "\n",
    "    # Compile neural network\n",
    "    network.compile(loss=\"categorical_crossentropy\", # Cross-entropy\n",
    "                    optimizer=optimizer, # Root Mean Square Propagation\n",
    "                    metrics=[\"accuracy\"]) # Accuracy performance metric\n",
    "    \n",
    "    return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1169b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "# Wrap Keras model so it can be used by scikit-learn\n",
    "neural_network = KerasClassifier(build_fn=create_network, verbose=1)\n",
    "\n",
    "# Create hyperparameter space\n",
    "epochs = [5, 10, 15]\n",
    "batches = [5, 25, 50, 100]\n",
    "optimizers = [\"rmsprop\", \"adam\"]\n",
    "\n",
    "# Create hyperparameter options\n",
    "hyperparameters = dict(optimizer=optimizers, epochs=epochs, batch_size=batches)\n",
    "\n",
    "# Create grid search\n",
    "grid = GridSearchCV(estimator=neural_network, param_grid=hyperparameters)\n",
    "\n",
    "# Fit grid search\n",
    "grid_result = grid.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99df1bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_result.best_param_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd74d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f925607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 14164003094718211814\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 2958177076\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 12060044751312880017\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce GTX 850M, pci bus id: 0000:01:00.0, compute capability: 5.0\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.add_dll_directory(\"C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v11.2/bin\")\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dff0d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "496.388px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
